#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –Ω–æ–≤–æ–π –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞.
"""

import os
import gc
from dotenv import load_dotenv
from pathlib import Path

from langchain_core.embeddings import Embeddings

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é
try:
    from gpu_utils import GPUMemoryManager, cleanup_gpu, monitor_gpu
    GPU_UTILS_AVAILABLE = True
    gpu_manager = GPUMemoryManager()
except ImportError:
    GPU_UTILS_AVAILABLE = False
    print("‚ö†Ô∏è  GPU —É—Ç–∏–ª–∏—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

# GPU detection and configuration
try:
    import torch
    GPU_AVAILABLE = torch.cuda.is_available()
    DEVICE = "cuda" if GPU_AVAILABLE else "cpu"
    print(f"üöÄ Device: {DEVICE}")
    if GPU_AVAILABLE:
        print(f"üì± GPU: {torch.cuda.get_device_name(0)}")
        print(f"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
except ImportError:
    GPU_AVAILABLE = False
    DEVICE = "cpu"
    print("‚ö†Ô∏è  PyTorch –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
from rag_base import RAGSystemFactory
from rag_python import PythonRAGSystem
from rag_universal import UniversalRAGSystem
from rag_javascript import JavaScriptRAGSystem
from rag_architecture import ArchitectureRAGSystem

# LangChain imports
from langchain_community.llms import YandexGPT
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.embeddings import HuggingFaceBgeEmbeddings


def load_model(model_name, local_dir="./models", wrapper_cls=HuggingFaceEmbeddings, use_gpu=None):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU.
    """
    if use_gpu is None:
        use_gpu = GPU_AVAILABLE

    local_path = Path(local_dir) / model_name.replace("/", "_")

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è GPU
    model_kwargs = {}
    encode_kwargs = {}

    if use_gpu and GPU_AVAILABLE:
        model_kwargs.update({
            'device': DEVICE,
            'trust_remote_code': True,
        })
        encode_kwargs.update({
            'batch_size': 32,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch_size –¥–ª—è GPU
        })
        print(f"üî• –ó–∞–≥—Ä—É–∂–∞–µ–º {model_name} –Ω–∞ GPU")
    else:
        model_kwargs.update({
            'device': 'cpu',
        })
        encode_kwargs.update({
            'batch_size': 8,  # –ú–µ–Ω—å—à–∏–π batch_size –¥–ª—è CPU
        })
        print(f"üêå –ó–∞–≥—Ä—É–∂–∞–µ–º {model_name} –Ω–∞ CPU")

    if local_path.exists():
        return wrapper_cls(
            model_name=str(local_path),
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
    else:
        emb = wrapper_cls(
            model_name=model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ
            if hasattr(emb, 'client'):
                emb.client.save(str(local_path))
            elif hasattr(emb, '_client'):
                emb._client.save(str(local_path))
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ: {e}")
        return emb


def create_rag_tool(
    project_path: str,
    embeddings: Embeddings,
    rag_type: str = "auto",
    use_gpu: bool = None,
    **config
):
    """
    –°–æ–∑–¥–∞–µ—Ç RAG –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞.
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        rag_type: –¢–∏–ø RAG —Å–∏—Å—Ç–µ–º—ã ("python", "universal", "auto")
        embeddings: –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        use_gpu: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (None = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
        **config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    """
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
    llm = YandexGPT(
        iam_token=os.getenv('YANDEX_GPT_API_KEY'),
        folder_id=os.getenv('YANDEX_GPT_FOLDER_ID'),
        model_name="yandexgpt"
    )
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞
    if rag_type == "auto":
        rag_type = RAGSystemFactory.detect_project_type(project_path)
        print(f"üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞: {rag_type}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏
    if GPU_UTILS_AVAILABLE and use_gpu:
        print("üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º RAG —Å–∏—Å—Ç–µ–º—ã:")
        monitor_gpu()
        if gpu_manager.check_memory_threshold(75):
            print("‚ö†Ô∏è  –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏, –≤—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É...")
            cleanup_gpu()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã
    print(f"üîß –°–æ–∑–¥–∞–µ–º {rag_type.upper()} RAG —Å–∏—Å—Ç–µ–º—É...")
    
    rag_system = RAGSystemFactory.create(
        rag_type,
        llm=llm,
        embeddings=embeddings,
        **config
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    tool = rag_system.create_tool(project_path)
    
    print(f"‚úÖ {rag_type.upper()} RAG –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤!")
    return tool